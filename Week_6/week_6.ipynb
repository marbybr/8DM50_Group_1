{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "## Dataset\n",
    "\n",
    "In this set of exercises we will use the same dataset as from [week 3](week_3.ipynb). \n",
    "\n",
    "\n",
    "As before, we provide the data already curated in the following two files:\n",
    "\n",
    "`RNA_expression_curated.csv`: [148 cell lines , 238 genes]\n",
    "\n",
    "`drug_response_curated.csv`: [148 cell lines , YM155 drug]\n",
    "\n",
    "The curated data can be read as `pandas` `DataFrame` in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:23:43.313824Z",
     "start_time": "2024-10-14T17:23:43.148657Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "gene_expression = pd.read_csv(\"data/RNA_expression_curated.csv\", sep=',', header=0, index_col=0)\n",
    "drug_response = pd.read_csv(\"./data/drug_response_curated.csv\", sep=',', header=0, index_col=0)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert numpy.ndarray to numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m gene_expression \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./data/RNA_expression_curated.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m drug_response \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/drug_response_curated.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1965\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1966\u001B[0m         new_col_dict \u001B[38;5;241m=\u001B[39m col_dict\n\u001B[1;32m-> 1968\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1969\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnew_col_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1973\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1975\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_currow \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m new_rows\n\u001B[0;32m   1976\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    772\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[0;32m    773\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[0;32m    774\u001B[0m     )\n\u001B[0;32m    776\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    777\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[1;32m--> 778\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mrecords\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:443\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    441\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mseries\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Series\n\u001B[1;32m--> 443\u001B[0m     arrays \u001B[38;5;241m=\u001B[39m \u001B[43mSeries\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mobject\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    444\u001B[0m     missing \u001B[38;5;241m=\u001B[39m arrays\u001B[38;5;241m.\u001B[39misna()\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    446\u001B[0m         \u001B[38;5;66;03m# GH10856\u001B[39;00m\n\u001B[0;32m    447\u001B[0m         \u001B[38;5;66;03m# raise ValueError if only scalars in dict\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:490\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[1;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[0;32m    487\u001B[0m name \u001B[38;5;241m=\u001B[39m ibase\u001B[38;5;241m.\u001B[39mmaybe_extract_name(name, data, \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m))\n\u001B[0;32m    489\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 490\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[43mensure_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    493\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_dtype(dtype)\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7647\u001B[0m, in \u001B[0;36mensure_index\u001B[1;34m(index_like, copy)\u001B[0m\n\u001B[0;32m   7645\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m MultiIndex\u001B[38;5;241m.\u001B[39mfrom_arrays(index_like)\n\u001B[0;32m   7646\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 7647\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mIndex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtupleize_cols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   7648\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   7649\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Index(index_like, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:565\u001B[0m, in \u001B[0;36mIndex.__new__\u001B[1;34m(cls, data, dtype, copy, name, tupleize_cols)\u001B[0m\n\u001B[0;32m    562\u001B[0m         data \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39masarray_tuplesafe(data, dtype\u001B[38;5;241m=\u001B[39m_dtype_obj)\n\u001B[0;32m    564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 565\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43msanitize_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    567\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex must be specified when data is not list-like\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(err):\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\core\\construction.py:654\u001B[0m, in \u001B[0;36msanitize_array\u001B[1;34m(data, index, dtype, copy, allow_2d)\u001B[0m\n\u001B[0;32m    651\u001B[0m     subarr \u001B[38;5;241m=\u001B[39m _try_cast(data, dtype, copy)\n\u001B[0;32m    653\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 654\u001B[0m     subarr \u001B[38;5;241m=\u001B[39m \u001B[43mmaybe_convert_platform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    655\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m subarr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m    656\u001B[0m         subarr \u001B[38;5;241m=\u001B[39m cast(np\u001B[38;5;241m.\u001B[39mndarray, subarr)\n",
      "File \u001B[1;32m~\\PycharmProjects\\8DM50_Group_1\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:139\u001B[0m, in \u001B[0;36mmaybe_convert_platform\u001B[1;34m(values)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m _dtype_obj:\n\u001B[0;32m    138\u001B[0m     arr \u001B[38;5;241m=\u001B[39m cast(np\u001B[38;5;241m.\u001B[39mndarray, arr)\n\u001B[1;32m--> 139\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_convert_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\n",
      "File \u001B[1;32mlib.pyx:2538\u001B[0m, in \u001B[0;36mpandas._libs.lib.maybe_convert_objects\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Cannot convert numpy.ndarray to numpy.ndarray"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the exercises is to train support vector machine (SVM) and random forests classifiers on this dataset and explore and learn about their hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The `scikit-learn` library provides the required tools for support vector machines, as well as for random forest algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets.samples_generator import make_blobs, make_circles\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, look up the documentation of the imported functions and read about their basic functionality. Below, we list some important parameters of SVMs and random forests that can be tuned during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)\n",
    "\n",
    "`C`: error term.\n",
    "\n",
    "`kernel`: similarity function ('linear', 'poly', 'sigmoid' or 'rbf')\n",
    "\n",
    "`gamma`: kernel coef. for 'rbf', 'poly' and 'sigmoid' kernels. It can be thought of as the ‘spread’ of the kernel and therefore the decision region.\n",
    "\n",
    "`degree`: degree for the 'poly' kernel.\n",
    "\n",
    "`coef0`: independt term in the 'poly' and 'sigmoid' kernels\n",
    "\n",
    "\n",
    "#### Random Forests\n",
    "\n",
    "`n_estimators`: number of trees in our random forest.\n",
    "\n",
    "`max_depth`: maximum number of levels in each decision tree\n",
    "\n",
    "`max_features`: maximum number of features to consider per split in an individual tree.\n",
    "\n",
    "`min_sample_leaf`: minimum number of data points per leaf node\n",
    "\n",
    "`min_samples_split`: minimum number of data points placed in a node before the node is split\n",
    "\n",
    "`oob_score`: the out-of-bag (OOB) error is the average error for each observation calculated using predictions from the trees that do not contain that observation in their respective bootstrap sample. Set this parameter to true.\n",
    "\n",
    "`bootstrap`: method for sampling data points (with or without replacement). Set this parameter to true.\n",
    "\n",
    "`criterion`: function used to measure the quality of the split (e.g. 'entropy' or 'gini')\n",
    "\n",
    "# Exercises\n",
    "\n",
    "## Support vector machines\n",
    "\n",
    "The  `make_blobs` and `make_circles` functions can be used to generate linearly and not linearly separable toy datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation: linearly separable\n",
    "X, Y = make_blobs(n_samples=200, centers=2, n_features=2, random_state=1234)\n",
    "X = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "\n",
    "# splitting data into training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code illustrates how to train a linear SVM classifier and plot the data points, the separating hyperplane, the support vectors and the margins that pass through them (considering the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# build the model\n",
    "model = svm.SVC(kernel='linear', random_state=33)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# get colors from qualitative colormap 'Paired'\n",
    "cmap = plt.cm.get_cmap('Paired')\n",
    "\n",
    "# plot data points\n",
    "ax.scatter(X_train.iloc[Y_train == 1, 0], X_train.iloc[Y_train == 1, 1],\n",
    "           c=[cmap(11)], label='1')\n",
    "ax.scatter(X_train.iloc[Y_train == 0, 0], X_train.iloc[Y_train == 0, 1],\n",
    "           c=[cmap(0)], label='0')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# plot the decision function\n",
    "# create grid to evaluate model\n",
    "x1_min, x1_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
    "x2_min, x2_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
    "\n",
    "XX, YY = np.meshgrid(np.arange(x1_min, x1_max, .2),\n",
    "                     np.arange(x2_min, x2_max, .2))\n",
    "\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# Establish the class for each point in the contour\n",
    "Z = model.predict(xy).reshape(XX.shape)\n",
    "\n",
    "# Visualization of the contour\n",
    "ax.contourf(XX, YY, Z, cmap='bwr', alpha=0.3)\n",
    "\n",
    "# plot support vectors, whose are responsible for building the margins\n",
    "ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k', marker='s')\n",
    "\n",
    "ax.axis([x1_min, x1_max, x2_min, x2_max])\n",
    "plt.axis('tight')\n",
    "plt.title('Linear kernel SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a radial basis function (RBF) SVM classifier with `gamma=0.5` and plot the results in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation: not linearly separable\n",
    "X, Y = make_circles(n_samples=200, noise=0.05, random_state=1234)\n",
    "X = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "\n",
    "# splitting data into training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color='#770a0a'>When should a RBF kernel be used over a linear kernel? Motivate your answer.</font></p>\n",
    "\n",
    "<p><font color='#770a0a'>Do we need to normalize the data before using a kernel function? Motivate your answer.\n",
    "</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting drug response on cell lines from gene expression data with SVMs\n",
    "\n",
    "Explore the hyper-parameter space of an SVM classifier with cross-validation for the Genomics of Drug Sensitivity in Cancer (GDSC) dataset. The`GridSearchCV` function can be used to specify a grid of parameter values with the `param_grid` parameter.\n",
    "\n",
    "Calculate the precision of your predictions, and compare your calculations with the results of `classification_report`, which displays many classification metrics.\n",
    "\n",
    "\n",
    "## Random forests\n",
    "\n",
    "Follow the same steps as for SVM. Compare the two algorithms and report which one has better performance.\n",
    "\n",
    "The random forests classifiers allows to perform feature selection. Evaluate the importance of features extracting the top 50 informative features. A bar plot (`plt.bar()`) can be a useful tool to visualize this. \n",
    "\n",
    "\n",
    "## Biomedical applications\n",
    "\n",
    "Driven by technological advances, there has recently been a dramatic increase in availability of biomedical data. Machine learning approaches are well suited to take advantage of this data and have been widely applied to many areas of biology. \n",
    "\n",
    "Example of these applications are genome annotation, biomarker identification, systems biology, genome data analysis, protein  function  prediction, protein  structure prediction, protein localization prediction, identification of protein interactions and drug discovery.\n",
    "\n",
    "SVM and RF methods are among the most popular machine learning methods applied in bioinformatics or computational biology.\n",
    "\n",
    "Perform a literature search and find a biomedical study in which SVM or RF is applied to obtain certain insights. <p><font color='#770a0a'>Explain the motivation behind using that specific algorithm in the study.\n",
    "</font></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
